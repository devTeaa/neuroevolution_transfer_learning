,notes,train_acc,train_loss,val_acc,val_loss
0,,0.59,1.3073,0.16,5.5121
1,,0.50,1.4646,0.25,5.2587
2,,0.51,1.4344,0.43,13.5391
3,,0.51,1.4250,0.43,4.6843
4,,0.48,1.3940,0.25,5.6491
5,,0.52,1.3798,0.24,5.1155
6,,0.55,1.2943,0.43,4.7077
7,created new Adam optimizer with LR: 0.00100000000000000002,0.52,1.3263,0.43,4.7662
8,,0.53,1.3014,0.43,6.8660
9,,0.55,1.2601,0.42,6.0520
10,,0.53,1.2581,0.42,6.3834
11,,0.55,1.1752,0.43,6.7958
12,,0.57,1.1913,0.08,5.8148
13,,0.56,1.1654,0.43,5.3203
14,,0.59,1.1714,0.43,7.1614
15,created new Adam optimizer with LR: 0.0001,0.59,1.1005,0.42,7.0885
16,,0.59,1.1005,0.43,6.6255
17,,0.60,1.0930,0.43,6.4314
18,,0.63,1.0388,0.43,6.9408
19,,0.64,1.0053,0.43,6.7462
20,,0.58,1.0425,0.43,7.2968
21,,0.61,1.0805,0.43,7.7145
22,,0.60,1.0306,0.43,7.8937
23,created new Adam optimizer with LR: 0.00001,0.65,1.0085,0.43,8.1093
24,,0.62,1.0292,0.43,8.0174
25,,0.61,0.9889,0.43,8.1470
26,,0.63,0.9815,0.43,8.3599
27,,0.64,0.9890,0.43,8.6959
28,,0.61,0.9722,0.42,8.9383
29,,0.63,0.9871,0.43,8.6864
30,,0.61,0.9895,0.42,8.0156
31,created new Adam optimizer with LR: 0.000001,0.60,1.0033,0.42,9.1023
32,,0.63,0.9771,0.43,8.4146
33,,0.63,0.9730,0.43,9.1361
34,,0.64,0.9712,0.43,9.5211
35,,0.63,1.0124,0.42,8.4976
36,,0.63,0.9730,0.43,8.7581
37,,0.63,1.0053,0.43,8.4367
38,,0.63,0.9671,0.43,8.7562
39,created new Adam optimizer with LR: 0.0000001,0.64,0.9727,0.43,8.7568
40,,0.64,0.9753,0.43,8.8397
41,,0.63,0.9714,0.43,8.8544
42,,0.63,1.0141,0.43,8.5013
43,,0.61,0.9747,0.43,8.1031
44,,0.63,0.9930,0.42,8.3474
45,,0.64,0.9569,0.43,8.7749
46,,0.62,1.0015,0.43,9.1593
47,created new Adam optimizer with LR: 0.00000001,0.63,0.9927,0.42,8.3777
48,,0.64,0.9857,0.43,8.8591
49,,0.62,0.9900,0.42,8.1184
