,notes,train_acc,train_loss,val_acc,val_loss
0,,0.40,2.5522,0.49,2.8303
1,,0.47,3.2648,0.31,12.0037
2,,0.47,4.5433,0.43,4.8350
3,,0.55,3.5892,0.46,4.5784
4,,0.55,4.4046,0.43,19.8250
5,,0.61,4.3392,0.53,9.4172
6,,0.64,3.6503,0.52,11.0995
7,,0.68,3.1489,0.47,11.1067
8,,0.70,3.6463,0.38,8.2714
9,,0.74,3.0147,0.63,7.8411
10,,0.72,3.7052,0.49,17.6401
11,,0.80,2.5697,0.32,24.5119
12,,0.79,3.3011,0.65,12.4266
13,,0.84,2.2782,0.63,11.9700
14,,0.86,1.9914,0.58,17.0002
15,,0.83,2.7864,0.47,29.0863
16,,0.80,4.5703,0.57,14.9572
17,,0.85,2.7488,0.61,19.7954
18,,0.88,2.2224,0.60,18.5698
19,,0.90,1.7347,0.59,17.0275
20,,0.92,1.3282,0.59,19.0466
21,,0.93,1.0251,0.65,37.6568
22,,0.94,1.1517,0.51,129.1665
23,,0.85,5.5471,0.57,39.0924
24,,0.93,1.5368,0.67,28.0680
25,,0.95,0.9528,0.64,32.9947
26,,0.94,0.9480,0.58,26.4470
27,,0.94,1.6308,0.63,45.7016
28,,0.96,0.8212,0.65,23.8604
29,created new Adam optimizer with LR: 0.00100000000000000002,0.94,1.4703,0.58,63.9021
30,,0.94,1.5793,0.69,29.2710
31,,0.96,0.9964,0.67,23.6215
32,,0.97,0.4464,0.66,23.4618
33,,0.98,0.3221,0.67,25.2223
34,,0.98,0.4844,0.67,24.1169
35,,0.98,0.2767,0.67,25.3666
36,,0.98,0.2787,0.65,24.8717
37,,0.98,0.3602,0.66,26.0713
38,,0.99,0.1789,0.66,26.2192
39,,0.99,0.1594,0.67,26.0963
40,,0.99,0.2105,0.67,27.4141
41,,0.98,0.1961,0.68,26.4350
42,,0.99,0.1221,0.67,27.8166
43,,0.99,0.1908,0.67,25.2248
44,,0.99,0.0890,0.68,26.1088
45,,0.99,0.1008,0.70,27.4061
46,,0.99,0.1097,0.66,26.2527
47,,0.99,0.1172,0.69,26.7943
48,,0.99,0.1085,0.69,24.5452
49,,0.99,0.1039,0.68,25.1795
