,notes,train_acc,train_loss,val_acc,val_loss
0,,0.43,1.6170,0.24,55.1876
1,,0.45,1.6457,0.24,73.6516
2,,0.51,1.5228,0.24,13.2046
3,,0.51,1.5106,0.25,15.6065
4,,0.53,1.5233,0.24,21.1443
5,,0.52,1.4340,0.42,8.9855
6,,0.53,1.5210,0.24,8.7398
7,,0.49,1.5220,0.24,27.7678
8,,0.53,1.4626,0.43,19.6112
9,,0.53,1.4137,0.24,18.2917
10,,0.52,1.3589,0.43,10.1637
11,,0.52,1.3496,0.43,9.2695
12,,0.56,1.3060,0.42,24.3156
13,,0.54,1.4261,0.43,10.8824
14,,0.52,1.4113,0.43,14.7948
15,,0.53,1.4665,0.42,22.1940
16,,0.52,1.3035,0.16,6.4594
17,,0.57,1.3012,0.24,14.9462
18,,0.56,1.2567,0.43,17.5342
19,,0.56,1.2869,0.43,13.2488
20,,0.56,1.2232,0.43,18.2046
21,,0.53,1.3051,0.42,11.1412
22,,0.58,1.2404,0.43,11.8891
23,,0.59,1.1655,0.16,30.2658
24,,0.59,1.1473,0.43,30.9355
25,,0.56,1.1760,0.24,14.1896
26,,0.56,1.3485,0.42,11.6533
27,,0.57,1.3314,0.42,25.5713
28,,0.60,1.1662,0.42,18.4011
29,created new Adam optimizer with LR: 0.00100000000000000002,0.61,1.1672,0.43,15.4302
30,,0.61,1.0452,0.43,11.4740
31,,0.63,0.9823,0.43,12.5598
32,,0.63,1.0068,0.43,13.4203
33,,0.66,0.8557,0.43,11.6086
34,,0.69,0.8511,0.42,12.2563
35,,0.65,0.9680,0.43,12.4791
36,,0.67,0.8365,0.43,11.2432
37,,0.70,0.8687,0.43,17.4474
38,,0.68,0.8497,0.42,12.2210
39,,0.70,0.8041,0.42,10.3826
40,,0.68,0.7995,0.43,12.7547
41,,0.68,0.7920,0.42,14.6760
42,,0.66,0.8362,0.42,14.2179
43,,0.71,0.7828,0.42,15.9792
44,,0.68,0.8513,0.43,11.2606
45,,0.72,0.7599,0.43,30.9436
46,,0.70,0.7551,0.43,14.5294
47,,0.70,0.7816,0.43,15.5483
48,,0.70,0.7614,0.43,19.9967
49,,0.68,0.7882,0.43,13.5613
