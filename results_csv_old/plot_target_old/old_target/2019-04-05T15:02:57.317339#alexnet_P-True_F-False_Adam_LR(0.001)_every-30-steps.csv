,notes,train_acc,train_loss,val_acc,val_loss
0,,0.40,1.6451,0.24,2.1105
1,,0.40,1.6214,0.24,1.5788
2,,0.39,1.5835,0.42,1.5903
3,,0.41,1.5698,0.43,1.5346
4,,0.41,1.5707,0.43,1.5624
5,,0.41,1.5891,0.42,1.5469
6,,0.43,1.5820,0.43,1.5248
7,,0.41,1.5688,0.43,1.5409
8,,0.43,1.5691,0.42,1.5256
9,,0.43,1.5611,0.43,1.5585
10,,0.41,1.5607,0.43,1.5783
11,,0.43,1.5847,0.43,1.5294
12,,0.39,1.5585,0.43,1.5402
13,,0.41,1.5610,0.43,1.5353
14,,0.43,1.5751,0.43,1.5281
15,,0.41,1.5615,0.43,1.5239
16,,0.41,1.5581,0.43,1.5339
17,,0.39,1.5667,0.43,1.5406
18,,0.39,1.5593,0.24,1.5642
19,,0.39,1.5753,0.43,1.5240
20,,0.41,1.5665,0.43,1.5265
21,,0.43,1.5639,0.43,1.5247
22,,0.45,1.5592,0.42,1.5400
23,,0.41,1.5709,0.43,1.5294
24,,0.43,1.5594,0.43,1.5240
25,,0.45,1.5610,0.42,1.5242
26,,0.41,1.5708,0.43,1.5226
27,,0.43,1.5617,0.43,1.5404
28,,0.41,1.5571,0.43,1.5326
29,created new Adam optimizer with LR: 0.00100000000000000002,0.41,1.5593,0.43,1.5243
30,,0.45,1.5605,0.43,1.5238
31,,0.43,1.5525,0.43,1.5233
32,,0.41,1.5519,0.43,1.5229
33,,0.39,1.5502,0.43,1.5229
34,,0.39,1.5500,0.43,1.5225
35,,0.45,1.5497,0.43,1.5221
36,,0.41,1.5501,0.43,1.5217
37,,0.39,1.5500,0.42,1.5217
38,,0.39,1.5503,0.42,1.5223
39,,0.39,1.5500,0.43,1.5230
40,,0.41,1.5502,0.43,1.5234
41,,0.39,1.5500,0.43,1.5232
42,,0.39,1.5500,0.43,1.5230
43,,0.41,1.5507,0.43,1.5226
44,,0.41,1.5499,0.43,1.5223
45,,0.43,1.5497,0.43,1.5217
46,,0.41,1.5503,0.43,1.5213
47,,0.41,1.5506,0.43,1.5214
48,,0.39,1.5505,0.43,1.5218
49,,0.41,1.5499,0.42,1.5219
50,,0.43,1.5499,0.43,1.5217
51,,0.41,1.5499,0.42,1.5219
52,,0.43,1.5495,0.43,1.5216
53,,0.41,1.5497,0.43,1.5213
54,,0.39,1.5507,0.42,1.5213
55,,0.41,1.5507,0.42,1.5214
56,,0.41,1.5502,0.43,1.5216
57,,0.39,1.5499,0.42,1.5222
58,,0.43,1.5502,0.43,1.5219
59,created new Adam optimizer with LR: 0.0001,0.43,1.5504,0.42,1.5216
60,,0.43,1.5504,0.43,1.5214
61,,0.39,1.5487,0.43,1.5214
62,,0.43,1.5488,0.43,1.5215
63,,0.43,1.5487,0.43,1.5215
64,,0.39,1.5487,0.43,1.5215
65,,0.43,1.5487,0.43,1.5215
66,,0.39,1.5487,0.43,1.5215
67,,0.43,1.5487,0.43,1.5215
68,,0.41,1.5487,0.43,1.5215
69,,0.39,1.5487,0.42,1.5215
70,,0.41,1.5487,0.43,1.5215
71,,0.41,1.5487,0.42,1.5215
72,,0.41,1.5487,0.42,1.5215
73,,0.39,1.5486,0.43,1.5215
74,,0.45,1.5487,0.43,1.5215
75,,0.41,1.5487,0.42,1.5215
76,,0.41,1.5487,0.42,1.5215
77,,0.39,1.5487,0.43,1.5215
78,,0.43,1.5487,0.43,1.5215
79,,0.39,1.5487,0.43,1.5215
80,,0.43,1.5487,0.43,1.5215
81,,0.39,1.5486,0.43,1.5215
82,,0.43,1.5486,0.43,1.5216
83,,0.41,1.5487,0.42,1.5215
84,,0.41,1.5487,0.43,1.5216
85,,0.41,1.5486,0.42,1.5216
86,,0.41,1.5486,0.43,1.5216
87,,0.41,1.5487,0.42,1.5216
88,,0.41,1.5486,0.43,1.5216
89,created new Adam optimizer with LR: 0.00001,0.39,1.5487,0.43,1.5216
90,,0.39,1.5487,0.43,1.5217
91,,0.41,1.5486,0.42,1.5217
92,,0.41,1.5486,0.42,1.5217
93,,0.41,1.5486,0.43,1.5217
94,,0.41,1.5486,0.43,1.5217
95,,0.43,1.5486,0.43,1.5217
96,,0.43,1.5486,0.43,1.5217
97,,0.43,1.5486,0.43,1.5217
98,,0.39,1.5486,0.43,1.5217
99,,0.45,1.5486,0.42,1.5217
