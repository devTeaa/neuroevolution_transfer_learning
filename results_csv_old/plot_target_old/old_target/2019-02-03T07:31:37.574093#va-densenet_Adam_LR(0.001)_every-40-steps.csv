,notes,train_acc,train_loss,val_acc,val_loss
0,,0.44,1.5354,0.51,1.3717
1,,0.47,1.3502,0.53,1.3134
2,,0.58,1.1520,0.40,1.6639
3,,0.61,1.0250,0.48,1.2694
4,,0.68,0.8774,0.61,1.1094
5,,0.67,0.9090,0.60,1.0534
6,,0.67,0.8545,0.46,1.1839
7,,0.69,0.7912,0.62,1.0702
8,,0.72,0.7643,0.66,1.0132
9,,0.72,0.7476,0.63,0.9665
10,,0.74,0.7011,0.60,1.0800
11,,0.76,0.6788,0.59,1.0949
12,,0.77,0.6298,0.62,1.0423
13,,0.73,0.7053,0.58,1.0103
14,,0.76,0.6531,0.64,1.0018
15,,0.77,0.5946,0.61,1.0911
16,,0.77,0.6106,0.64,1.0084
17,,0.79,0.5592,0.52,1.2851
18,,0.74,0.6728,0.59,1.1165
19,,0.76,0.5999,0.62,1.0491
20,,0.82,0.4858,0.60,1.2582
21,,0.80,0.5650,0.58,1.0846
22,,0.82,0.5107,0.63,1.0258
23,,0.82,0.5249,0.57,1.1031
24,,0.77,0.5970,0.54,1.2529
25,,0.78,0.5580,0.59,1.1686
26,,0.83,0.4750,0.55,1.1272
27,,0.78,0.5898,0.62,1.2259
28,,0.81,0.5124,0.58,1.2634
29,,0.80,0.5317,0.57,1.1722
30,,0.85,0.4606,0.62,1.0336
31,,0.84,0.4572,0.59,1.1400
32,,0.80,0.5204,0.61,0.9559
33,,0.83,0.4543,0.60,1.1856
34,,0.79,0.5365,0.65,1.1345
35,,0.84,0.4501,0.62,1.0214
36,,0.83,0.4418,0.64,1.1299
37,,0.81,0.5241,0.55,1.1707
38,,0.80,0.5200,0.58,1.1857
39,created new Adam optimizer with LR: 0.00100000000000000002,0.82,0.4654,0.56,1.2244
40,,0.84,0.4482,0.59,1.0880
41,,0.84,0.4437,0.60,1.1249
42,,0.87,0.3617,0.59,1.2481
43,,0.86,0.4018,0.59,1.2485
44,,0.86,0.4034,0.63,1.2241
45,,0.87,0.3901,0.58,1.1857
46,,0.84,0.4186,0.58,1.1401
47,,0.85,0.4178,0.59,1.0850
48,,0.86,0.3892,0.59,1.1092
49,,0.84,0.4192,0.62,1.1880
50,,0.86,0.3919,0.58,1.3040
51,,0.86,0.3891,0.62,1.1057
52,,0.84,0.4281,0.59,1.0983
53,,0.84,0.4205,0.61,1.0157
54,,0.86,0.4070,0.57,1.0749
55,,0.85,0.4058,0.64,1.1192
56,,0.85,0.4110,0.64,1.1541
57,,0.85,0.4058,0.60,1.1733
58,,0.87,0.3741,0.62,1.1521
59,,0.87,0.3613,0.56,1.0455
60,,0.84,0.4235,0.62,1.1321
61,,0.86,0.4062,0.58,1.2736
62,,0.83,0.4624,0.60,1.0556
63,,0.87,0.3564,0.57,1.1474
64,,0.85,0.4218,0.58,1.1774
65,,0.86,0.3878,0.59,1.2096
66,,0.84,0.4384,0.57,1.0611
67,,0.87,0.3846,0.66,1.1655
68,,0.87,0.3739,0.63,1.0543
69,,0.87,0.3706,0.65,1.1003
70,,0.86,0.3841,0.57,1.2482
71,,0.88,0.3514,0.61,1.1645
72,,0.85,0.4064,0.56,1.3321
73,,0.85,0.4277,0.63,1.1179
74,,0.82,0.4460,0.64,1.2320
75,,0.85,0.4265,0.64,1.1155
76,,0.85,0.4118,0.61,1.1117
77,,0.84,0.4366,0.58,1.3669
78,,0.86,0.3724,0.65,1.2132
79,created new Adam optimizer with LR: 0.0001,0.84,0.4413,0.64,1.1713
80,,0.86,0.3715,0.64,1.0832
81,,0.86,0.3796,0.61,1.2549
82,,0.86,0.3832,0.59,1.1272
83,,0.86,0.3652,0.60,1.2741
84,,0.86,0.3776,0.62,1.1419
85,,0.87,0.3877,0.59,1.1671
86,,0.85,0.4165,0.62,1.1059
87,,0.88,0.3767,0.57,1.1370
88,,0.85,0.4070,0.62,1.4185
89,,0.86,0.3977,0.61,1.2476
90,,0.85,0.4344,0.59,1.1825
91,,0.85,0.4175,0.63,1.0651
92,,0.89,0.3483,0.59,1.0869
93,,0.85,0.3904,0.64,1.0653
94,,0.85,0.3977,0.63,1.1815
95,,0.86,0.3980,0.61,1.1204
96,,0.86,0.3818,0.63,1.1937
97,,0.88,0.3585,0.66,1.0809
98,,0.85,0.4165,0.63,1.0018
99,,0.86,0.3819,0.63,1.1197
