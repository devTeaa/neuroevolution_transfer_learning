epochs,notes,train_acc,train_loss,val_acc,val_loss
0,,0.50,1.5391,0.56,1.5086
1,,0.60,1.1338,0.46,1.7495
2,,0.66,0.9422,0.52,1.4352
3,,0.75,0.6410,0.56,1.3026
4,,0.68,0.9279,0.49,1.5089
5,,0.72,0.7486,0.66,1.2274
6,created new Adam optimizer with LR: 0.00100000000000000002,0.75,0.7628,0.41,2.3781
7,,0.74,0.7122,0.60,1.6019
8,,0.81,0.5141,0.67,1.0002
9,,0.82,0.4922,0.60,1.1090
10,,0.80,0.4804,0.60,1.0823
11,,0.83,0.4795,0.64,0.9959
12,,0.83,0.4405,0.60,1.0642
13,created new Adam optimizer with LR: 0.0001,0.81,0.4951,0.68,0.9918
14,,0.81,0.4722,0.62,1.1103
15,,0.82,0.4474,0.63,0.9780
16,,0.85,0.4193,0.59,1.0433
17,,0.82,0.4777,0.59,1.1011
18,,0.87,0.3868,0.57,1.2090
19,,0.86,0.3816,0.61,1.0737
20,created new Adam optimizer with LR: 0.00001,0.86,0.3945,0.62,1.0435
21,,0.84,0.4424,0.65,0.9275
22,,0.84,0.4183,0.64,0.9907
23,,0.86,0.3928,0.58,1.0203
24,,0.85,0.4041,0.57,1.0454
25,,0.85,0.4076,0.53,1.3879
26,,0.83,0.4262,0.60,1.0576
27,created new Adam optimizer with LR: 0.000001,0.86,0.3889,0.59,1.1013
28,,0.81,0.4648,0.60,1.1010
29,,0.84,0.4086,0.64,1.0667
30,,0.86,0.3798,0.63,1.0168
31,,0.84,0.4053,0.60,1.0708
32,,0.84,0.4330,0.54,1.1826
33,,0.85,0.3815,0.61,1.1893
34,created new Adam optimizer with LR: 0.0000001,0.86,0.3637,0.61,1.0275
35,,0.84,0.4010,0.62,1.0858
36,,0.84,0.4258,0.62,0.9689
37,,0.86,0.3734,0.63,1.0175
38,,0.86,0.3758,0.61,1.0014
39,,0.84,0.4240,0.60,1.0614
40,,0.84,0.4215,0.61,1.1431
41,created new Adam optimizer with LR: 0.00000001,0.84,0.4246,0.59,1.0811
42,,0.86,0.3906,0.61,1.0987
43,,0.84,0.4463,0.59,1.2239
44,,0.85,0.4063,0.54,1.1936
45,,0.87,0.3889,0.57,1.0139
46,,0.85,0.3927,0.60,1.1666
47,,0.86,0.3858,0.59,1.0080
48,created new Adam optimizer with LR: 0.000000001,0.86,0.3844,0.60,1.0499
49,,0.86,0.4048,0.59,1.0514
50,,0.84,0.4242,0.66,1.0071
51,,0.84,0.4251,0.64,1.0440
52,,0.86,0.3931,0.55,1.1914
53,,0.83,0.4522,0.65,0.9611
54,,0.83,0.4556,0.58,1.2102
55,created new Adam optimizer with LR: 0.0000000001,0.86,0.3487,0.61,1.0545
56,,0.85,0.4059,0.60,1.0810
57,,0.83,0.4193,0.63,1.0003
58,,0.86,0.3838,0.52,1.2538
59,,0.86,0.4052,0.65,0.9797
60,,0.81,0.4868,0.58,1.1617
61,,0.85,0.4172,0.63,1.0368
62,created new Adam optimizer with LR: 0.00000000001,0.84,0.4415,0.61,1.1565
63,,0.83,0.4350,0.57,1.2440
64,,0.85,0.4014,0.63,1.0002
65,,0.85,0.4089,0.55,1.0958
66,,0.84,0.4408,0.60,1.0763
67,,0.81,0.4823,0.61,1.1089
68,,0.85,0.4095,0.59,1.1197
69,created new Adam optimizer with LR: 0.000000000001,0.86,0.4055,0.63,1.0693
70,,0.84,0.4257,0.65,0.9137
71,,0.85,0.4295,0.60,0.9730
72,,0.87,0.3790,0.64,0.9827
73,,0.85,0.4130,0.63,1.0350
74,,0.83,0.4453,0.62,0.9963
75,,0.85,0.3954,0.53,1.3469
76,created new Adam optimizer with LR: 0.0000000000001,0.85,0.3953,0.59,1.0876
77,,0.86,0.3691,0.62,1.1235
78,,0.84,0.4414,0.61,0.9862
79,,0.83,0.4361,0.65,1.2311
80,,0.88,0.3568,0.61,0.9859
81,,0.82,0.4682,0.63,1.0918
82,,0.85,0.4083,0.61,1.0356
83,created new Adam optimizer with LR: 0.00000000000001,0.85,0.4357,0.58,1.1796
84,,0.85,0.4177,0.64,0.9839
85,,0.84,0.4206,0.60,1.0470
86,,0.81,0.4641,0.56,1.1833
87,,0.84,0.4267,0.58,1.0523
88,,0.84,0.4113,0.57,1.0664
89,,0.87,0.3686,0.56,1.1358
90,created new Adam optimizer with LR: 0.000000000000001,0.85,0.4021,0.62,1.0189
91,,0.85,0.4114,0.60,1.0115
92,,0.84,0.4349,0.60,1.1073
93,,0.85,0.3890,0.60,1.1545
94,,0.83,0.4270,0.62,0.9789
95,,0.84,0.4357,0.62,1.2097
96,,0.80,0.5094,0.63,1.1491
97,created new Adam optimizer with LR: 0.0000000000000001,0.85,0.4237,0.57,1.0978
98,,0.86,0.3748,0.61,0.9673
99,,0.83,0.4669,0.60,1.1126
