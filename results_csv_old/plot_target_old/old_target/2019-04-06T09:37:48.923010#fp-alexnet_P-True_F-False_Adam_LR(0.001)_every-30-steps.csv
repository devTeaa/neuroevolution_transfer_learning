,notes,train_acc,train_loss,val_acc,val_loss
0,,0.40,1.6152,0.43,2.0021
1,,0.38,1.6216,0.42,1.5444
2,,0.38,1.5875,0.43,1.5549
3,,0.35,1.5867,0.43,1.5408
4,,0.40,1.5773,0.43,1.5536
5,,0.43,1.5654,0.43,1.6752
6,,0.39,1.5857,0.43,1.5328
7,,0.41,1.5707,0.42,1.5351
8,,0.41,1.5713,0.42,1.5257
9,,0.43,1.5649,0.43,1.5331
10,,0.43,1.5671,0.42,1.5402
11,,0.41,1.5660,0.42,1.5314
12,,0.41,1.5605,0.43,1.5454
13,,0.41,1.5822,0.43,1.5362
14,,0.43,1.5583,0.42,1.5329
15,,0.41,1.5684,0.43,1.5295
16,,0.43,1.5634,0.43,1.5342
17,,0.39,1.5623,0.42,1.5396
18,,0.38,1.5662,0.42,1.5529
19,,0.43,1.5668,0.42,1.5257
20,,0.41,1.5656,0.43,1.5353
21,,0.43,1.5675,0.43,1.5318
22,,0.41,1.5672,0.43,1.5267
23,,0.39,1.5639,0.43,1.5301
24,,0.39,1.5656,0.43,1.5377
25,,0.43,1.5645,0.42,1.5344
26,,0.43,1.5599,0.42,1.5282
27,,0.41,1.5554,0.42,1.5229
28,,0.41,1.5626,0.43,1.5220
29,created new Adam optimizer with LR: 0.00100000000000000002,0.39,1.5573,0.43,1.5227
30,,0.41,1.5633,0.43,1.5245
31,,0.41,1.5515,0.43,1.5234
32,,0.39,1.5501,0.43,1.5230
33,,0.39,1.5509,0.43,1.5229
34,,0.39,1.5506,0.43,1.5231
35,,0.41,1.5503,0.43,1.5228
36,,0.41,1.5500,0.43,1.5226
37,,0.41,1.5510,0.43,1.5224
38,,0.41,1.5501,0.42,1.5221
39,,0.43,1.5508,0.43,1.5219
40,,0.41,1.5501,0.43,1.5216
41,,0.45,1.5501,0.43,1.5214
42,,0.43,1.5500,0.42,1.5213
43,,0.39,1.5497,0.42,1.5215
44,,0.43,1.5497,0.43,1.5218
45,,0.43,1.5503,0.43,1.5216
46,,0.41,1.5495,0.43,1.5217
47,,0.41,1.5500,0.43,1.5217
48,,0.41,1.5499,0.43,1.5215
49,,0.43,1.5500,0.43,1.5216
50,,0.43,1.5499,0.43,1.5216
51,,0.43,1.5498,0.43,1.5216
52,,0.41,1.5499,0.43,1.5219
53,,0.41,1.5503,0.43,1.5222
54,,0.43,1.5501,0.42,1.5218
55,,0.43,1.5503,0.43,1.5215
56,,0.39,1.5510,0.43,1.5216
57,,0.41,1.5497,0.43,1.5217
58,,0.41,1.5500,0.43,1.5219
59,created new Adam optimizer with LR: 0.0001,0.43,1.5501,0.42,1.5216
60,,0.41,1.5501,0.43,1.5215
61,,0.39,1.5488,0.42,1.5215
62,,0.41,1.5488,0.43,1.5216
63,,0.41,1.5488,0.43,1.5216
64,,0.41,1.5487,0.43,1.5216
65,,0.43,1.5488,0.43,1.5216
66,,0.45,1.5488,0.43,1.5216
67,,0.41,1.5488,0.43,1.5216
68,,0.41,1.5488,0.42,1.5216
69,,0.45,1.5488,0.43,1.5215
70,,0.43,1.5488,0.43,1.5215
71,,0.41,1.5489,0.43,1.5215
72,,0.43,1.5489,0.42,1.5215
73,,0.41,1.5489,0.42,1.5215
74,,0.39,1.5488,0.43,1.5215
75,,0.41,1.5487,0.43,1.5216
76,,0.41,1.5489,0.42,1.5216
77,,0.39,1.5488,0.43,1.5216
78,,0.41,1.5488,0.43,1.5216
79,,0.41,1.5488,0.43,1.5216
80,,0.39,1.5488,0.42,1.5217
81,,0.39,1.5487,0.43,1.5217
82,,0.39,1.5488,0.43,1.5218
83,,0.45,1.5487,0.43,1.5218
84,,0.41,1.5487,0.43,1.5217
85,,0.43,1.5487,0.43,1.5217
86,,0.41,1.5488,0.42,1.5217
87,,0.43,1.5487,0.43,1.5216
88,,0.41,1.5488,0.43,1.5216
89,created new Adam optimizer with LR: 0.00001,0.43,1.5487,0.43,1.5217
90,,0.39,1.5487,0.43,1.5217
91,,0.43,1.5486,0.43,1.5217
92,,0.41,1.5486,0.43,1.5217
93,,0.43,1.5486,0.43,1.5217
94,,0.41,1.5486,0.43,1.5217
95,,0.41,1.5486,0.43,1.5217
96,,0.43,1.5486,0.43,1.5217
97,,0.43,1.5486,0.43,1.5217
98,,0.41,1.5486,0.43,1.5217
99,,0.43,1.5486,0.43,1.5217
