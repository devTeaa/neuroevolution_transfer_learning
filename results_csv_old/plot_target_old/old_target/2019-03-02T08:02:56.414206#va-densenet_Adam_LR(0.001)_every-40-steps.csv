,notes,train_acc,train_loss,val_acc,val_loss
0,,0.47,1.4850,0.41,1.5043
1,,0.57,1.2510,0.56,1.4108
2,,0.62,1.0881,0.60,1.1318
3,,0.65,0.9449,0.55,1.2790
4,,0.68,0.9040,0.51,1.1520
5,,0.68,0.8801,0.61,1.1851
6,,0.72,0.7738,0.58,1.0453
7,,0.72,0.7674,0.55,1.1884
8,,0.73,0.7248,0.54,1.2922
9,,0.72,0.7849,0.62,1.1317
10,,0.68,0.8076,0.60,1.0609
11,,0.75,0.6469,0.58,1.2439
12,,0.74,0.6662,0.44,1.3721
13,,0.75,0.6724,0.57,1.0741
14,,0.78,0.6023,0.62,1.0138
15,,0.79,0.5403,0.61,1.1770
16,,0.77,0.6578,0.60,1.1050
17,,0.78,0.5989,0.62,1.1780
18,,0.77,0.6287,0.59,1.0691
19,,0.79,0.5824,0.60,1.0447
20,,0.77,0.6071,0.60,1.1727
21,,0.78,0.5508,0.59,1.2795
22,,0.79,0.5668,0.58,1.1060
23,,0.80,0.5251,0.62,1.1678
24,,0.78,0.5631,0.65,1.0330
25,,0.84,0.4496,0.63,1.0819
26,,0.82,0.5013,0.55,1.2894
27,,0.83,0.4827,0.65,1.0463
28,,0.81,0.5172,0.56,1.2495
29,,0.82,0.5123,0.59,1.1736
30,,0.82,0.4695,0.67,1.0158
31,,0.83,0.4556,0.65,1.3071
32,,0.80,0.5331,0.59,1.1796
33,,0.84,0.4407,0.51,1.2041
34,,0.78,0.5741,0.60,1.3122
35,,0.82,0.4694,0.61,1.1669
36,,0.85,0.4282,0.61,1.2819
37,,0.82,0.4386,0.57,1.2475
38,,0.82,0.4471,0.55,1.4504
39,created new Adam optimizer with LR: 0.00100000000000000002,0.83,0.4748,0.66,1.1188
40,,0.81,0.5008,0.66,1.0405
41,,0.85,0.4390,0.68,1.1164
42,,0.85,0.3875,0.61,1.1761
43,,0.85,0.4171,0.69,1.0749
44,,0.85,0.4158,0.58,1.1317
45,,0.83,0.4320,0.64,1.0659
46,,0.86,0.3763,0.60,1.1372
47,,0.84,0.4462,0.58,1.1895
48,,0.85,0.3948,0.55,1.3737
49,,0.88,0.3517,0.63,1.3284
50,,0.85,0.4124,0.57,1.1404
51,,0.85,0.4197,0.62,1.2982
52,,0.85,0.3937,0.59,1.1924
53,,0.86,0.3845,0.67,1.1559
54,,0.85,0.4048,0.62,1.1445
55,,0.84,0.4030,0.60,1.1954
56,,0.84,0.4050,0.59,1.1771
57,,0.87,0.3961,0.62,1.1782
58,,0.85,0.4008,0.60,1.3834
59,,0.82,0.4446,0.56,1.4309
60,,0.83,0.4359,0.64,1.1275
61,,0.85,0.4180,0.57,1.1928
62,,0.87,0.3610,0.64,1.1585
63,,0.83,0.4105,0.57,1.3325
64,,0.85,0.3834,0.61,1.2645
65,,0.82,0.4768,0.61,1.2046
66,,0.86,0.3884,0.63,1.2062
67,,0.85,0.3840,0.65,1.1972
68,,0.85,0.4321,0.62,1.0851
69,,0.84,0.4259,0.66,1.0874
70,,0.85,0.3897,0.61,1.1994
71,,0.84,0.4178,0.54,1.2990
72,,0.86,0.3609,0.52,1.2647
73,,0.86,0.3721,0.60,1.1203
74,,0.85,0.3975,0.62,1.1091
75,,0.85,0.4183,0.67,1.0203
76,,0.86,0.3886,0.58,1.2740
77,,0.84,0.4050,0.67,1.0163
78,,0.88,0.3560,0.60,1.1745
79,created new Adam optimizer with LR: 0.0001,0.84,0.4018,0.66,1.1421
80,,0.88,0.3618,0.64,1.1434
81,,0.87,0.3852,0.61,1.1124
82,,0.85,0.4019,0.60,1.1543
83,,0.85,0.3999,0.59,1.3229
84,,0.86,0.3835,0.61,1.2133
85,,0.85,0.4015,0.66,1.1818
86,,0.86,0.3879,0.67,1.2046
87,,0.86,0.3827,0.60,1.0908
88,,0.85,0.3924,0.59,1.1682
89,,0.87,0.3437,0.65,1.1519
90,,0.83,0.4351,0.61,1.3271
91,,0.86,0.3954,0.55,1.4585
92,,0.85,0.3772,0.57,1.5168
93,,0.83,0.4245,0.64,1.1631
94,,0.86,0.3788,0.66,1.1051
95,,0.84,0.3943,0.58,1.2339
96,,0.88,0.3639,0.65,1.1884
97,,0.87,0.3642,0.61,1.2697
98,,0.85,0.4216,0.50,1.5330
99,,0.84,0.3990,0.65,1.1037
