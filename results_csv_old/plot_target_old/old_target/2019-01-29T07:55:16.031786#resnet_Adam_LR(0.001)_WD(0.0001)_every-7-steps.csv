epochs,notes,train_acc,train_loss,val_acc,val_loss
0,,0.55,1.5290,0.17,5.4836
1,,0.67,1.0485,0.16,10.6436
2,,0.64,1.4185,0.44,2.2307
3,,0.72,0.8490,0.62,1.1029
4,,0.73,0.8472,0.54,1.8751
5,,0.74,0.8776,0.38,3.5845
6,created new Adam optimizer with LR: 0.00100000000000000002,0.71,1.0330,0.55,2.4236
7,,0.78,0.7082,0.65,1.9414
8,,0.82,0.4939,0.63,1.2471
9,,0.84,0.4163,0.57,1.3621
10,,0.82,0.4664,0.58,1.2690
11,,0.82,0.4727,0.60,2.3810
12,,0.82,0.4425,0.65,1.1212
13,created new Adam optimizer with LR: 0.0001,0.81,0.4702,0.67,1.0691
14,,0.78,0.5549,0.63,1.3892
15,,0.85,0.3894,0.65,1.0968
16,,0.83,0.4148,0.64,1.0004
17,,0.86,0.3580,0.66,1.0054
18,,0.83,0.4109,0.64,1.2860
19,,0.84,0.4088,0.59,1.7780
20,created new Adam optimizer with LR: 0.00001,0.82,0.4522,0.61,2.0848
21,,0.86,0.3859,0.64,1.0416
22,,0.85,0.3889,0.67,0.9837
23,,0.83,0.4426,0.68,0.9016
24,,0.86,0.3669,0.62,1.2807
25,,0.83,0.4564,0.66,1.1507
26,,0.84,0.4149,0.63,1.1221
27,created new Adam optimizer with LR: 0.000001,0.86,0.3762,0.64,1.0765
28,,0.86,0.3743,0.58,9.6263
29,,0.85,0.3694,0.68,0.9568
30,,0.80,0.4747,0.68,0.9735
31,,0.85,0.3980,0.67,1.0139
32,,0.84,0.4157,0.61,1.2666
33,,0.84,0.4188,0.72,0.9492
34,created new Adam optimizer with LR: 0.0000001,0.84,0.3993,0.66,1.0607
35,,0.85,0.4190,0.67,0.9776
36,,0.83,0.4382,0.72,0.9192
37,,0.85,0.3861,0.61,1.2971
38,,0.82,0.4429,0.64,1.1951
39,,0.84,0.4017,0.66,1.2742
40,,0.85,0.4097,0.63,1.6029
41,created new Adam optimizer with LR: 0.00000001,0.85,0.3873,0.65,0.9264
42,,0.83,0.4518,0.71,0.9218
43,,0.85,0.4133,0.62,1.1121
44,,0.85,0.3676,0.62,1.4110
45,,0.84,0.4330,0.65,1.2014
46,,0.84,0.4249,0.63,1.5492
47,,0.86,0.3485,0.65,1.0855
48,created new Adam optimizer with LR: 0.000000001,0.86,0.3904,0.65,2.4102
49,,0.83,0.4149,0.71,0.9662
50,,0.82,0.4520,0.58,2.6863
51,,0.83,0.4087,0.70,0.9426
52,,0.82,0.4719,0.58,2.4108
53,,0.84,0.3955,0.68,1.0692
54,,0.83,0.4445,0.63,1.3348
55,created new Adam optimizer with LR: 0.0000000001,0.85,0.3547,0.62,1.2055
56,,0.85,0.3840,0.64,1.3800
57,,0.86,0.3493,0.70,0.9788
58,,0.84,0.3982,0.58,2.0957
59,,0.84,0.4076,0.60,2.4548
60,,0.84,0.4260,0.62,1.2289
61,,0.83,0.4096,0.66,1.1375
62,created new Adam optimizer with LR: 0.00000000001,0.82,0.4446,0.51,1.8429
63,,0.84,0.4024,0.67,1.1457
64,,0.82,0.4318,0.61,2.6362
65,,0.84,0.3885,0.59,1.8120
66,,0.85,0.3899,0.68,1.0205
67,,0.84,0.4163,0.65,1.2700
68,,0.83,0.4132,0.60,1.1312
69,created new Adam optimizer with LR: 0.000000000001,0.85,0.3935,0.60,1.6611
70,,0.86,0.3772,0.66,1.3053
71,,0.84,0.4080,0.63,1.2539
72,,0.85,0.3713,0.65,1.3176
73,,0.84,0.4054,0.62,1.0752
74,,0.84,0.3814,0.64,0.9651
75,,0.87,0.3431,0.67,0.9565
76,created new Adam optimizer with LR: 0.0000000000001,0.84,0.4415,0.68,1.4153
77,,0.83,0.4092,0.66,1.3976
78,,0.83,0.4300,0.69,0.9699
79,,0.83,0.4524,0.58,2.4651
80,,0.85,0.3733,0.69,0.8688
81,,0.83,0.4230,0.69,0.9811
82,,0.83,0.4357,0.58,1.2495
83,created new Adam optimizer with LR: 0.00000000000001,0.82,0.4391,0.70,0.9199
84,,0.85,0.4181,0.54,2.7886
85,,0.83,0.4231,0.72,0.7817
86,,0.83,0.4242,0.66,1.0632
87,,0.84,0.3792,0.69,0.9057
88,,0.83,0.4086,0.57,2.0715
89,,0.87,0.3426,0.61,3.2882
90,created new Adam optimizer with LR: 0.000000000000001,0.84,0.3983,0.60,1.4950
91,,0.82,0.4375,0.65,1.0077
92,,0.86,0.4238,0.64,1.7132
93,,0.84,0.3808,0.62,1.3110
94,,0.84,0.3887,0.67,1.0940
95,,0.86,0.3488,0.67,1.0538
96,,0.83,0.4412,0.67,0.9241
97,created new Adam optimizer with LR: 0.0000000000000001,0.85,0.3768,0.66,1.1805
98,,0.85,0.4069,0.70,1.0032
99,,0.83,0.4507,0.58,1.8434
