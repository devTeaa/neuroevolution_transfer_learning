,notes,train_acc,train_loss,val_acc,val_loss
0,,0.42,1.6639,0.49,1.4105
1,,0.54,1.3017,0.60,1.6077
2,,0.61,1.1259,0.51,1.3532
3,,0.62,1.0723,0.59,1.1921
4,,0.63,1.0387,0.54,1.1877
5,,0.67,0.9179,0.51,1.3282
6,,0.64,0.9648,0.53,1.4411
7,,0.70,0.8514,0.56,1.1916
8,,0.66,0.9148,0.55,1.6669
9,,0.66,0.9341,0.58,1.2578
10,,0.69,0.8477,0.61,1.1659
11,,0.67,0.9127,0.58,1.3393
12,,0.70,0.8155,0.60,1.2933
13,,0.73,0.7514,0.57,1.5986
14,,0.71,0.7918,0.59,1.1832
15,,0.73,0.7381,0.60,1.3598
16,,0.74,0.7233,0.62,1.4647
17,,0.73,0.7151,0.57,1.2015
18,,0.74,0.7113,0.60,1.3663
19,,0.73,0.7238,0.58,1.2428
20,,0.76,0.6786,0.59,1.4498
21,,0.75,0.6786,0.61,1.5907
22,,0.73,0.7335,0.57,1.6004
23,,0.75,0.6761,0.54,1.6395
24,,0.77,0.6444,0.57,1.4273
25,,0.75,0.6698,0.59,1.2959
26,,0.75,0.7381,0.58,1.5665
27,,0.77,0.6738,0.57,1.8786
28,,0.76,0.6529,0.61,1.5901
29,,0.76,0.6566,0.55,1.6290
30,,0.74,0.6832,0.56,1.4344
31,,0.79,0.6064,0.55,1.3415
32,,0.77,0.6324,0.54,1.3832
33,,0.73,0.7340,0.59,1.3339
34,,0.77,0.6486,0.56,1.5836
35,,0.76,0.6456,0.63,1.2276
36,,0.75,0.6825,0.61,1.2996
37,,0.77,0.6118,0.55,1.9688
38,,0.76,0.6428,0.58,1.9242
39,created new Adam optimizer with LR: 0.00100000000000000002,0.77,0.6650,0.58,1.6538
40,,0.74,0.7061,0.55,1.7600
41,,0.79,0.6112,0.61,1.2401
42,,0.78,0.5798,0.60,1.2721
43,,0.78,0.5991,0.62,1.2989
44,,0.82,0.5081,0.60,1.3293
45,,0.79,0.5714,0.60,1.1869
46,,0.75,0.6340,0.57,1.2785
47,,0.79,0.5638,0.60,1.3721
48,,0.81,0.5227,0.61,1.6509
49,,0.79,0.5726,0.60,1.5393
50,,0.76,0.6675,0.64,1.1676
51,,0.80,0.5695,0.58,1.3889
52,,0.80,0.5451,0.63,1.3477
53,,0.81,0.5335,0.55,1.2909
54,,0.79,0.5571,0.62,1.3291
55,,0.80,0.5467,0.59,1.5500
56,,0.81,0.5373,0.60,1.3191
57,,0.79,0.5683,0.59,1.4263
58,,0.80,0.5686,0.56,1.8435
59,,0.81,0.5599,0.58,1.4037
60,,0.81,0.5417,0.58,1.6066
61,,0.81,0.5332,0.60,1.2355
62,,0.81,0.5470,0.61,1.2820
63,,0.81,0.5249,0.61,1.3050
64,,0.81,0.5236,0.57,1.6138
65,,0.80,0.5520,0.58,1.5888
66,,0.79,0.5509,0.56,1.7551
67,,0.77,0.5867,0.61,1.3075
68,,0.82,0.5235,0.61,1.3009
69,,0.81,0.5611,0.56,1.4154
70,,0.82,0.5016,0.61,1.3038
71,,0.82,0.4967,0.54,1.7157
72,,0.82,0.5168,0.58,1.2598
73,,0.80,0.5222,0.59,1.5222
74,,0.79,0.5612,0.62,1.3532
75,,0.81,0.5246,0.68,1.2493
76,,0.78,0.6034,0.57,1.5568
77,,0.80,0.5920,0.55,1.6070
78,,0.79,0.5540,0.62,1.3257
79,created new Adam optimizer with LR: 0.0001,0.81,0.5251,0.57,1.2153
80,,0.82,0.5170,0.58,1.3704
81,,0.81,0.5239,0.61,1.2517
82,,0.82,0.5263,0.59,1.3344
83,,0.83,0.4957,0.59,1.5275
84,,0.82,0.5294,0.59,1.3632
85,,0.80,0.5507,0.59,1.3613
86,,0.80,0.5552,0.61,1.3144
87,,0.81,0.5210,0.61,1.2585
88,,0.80,0.5225,0.61,1.1716
89,,0.82,0.5190,0.55,1.9027
90,,0.81,0.5002,0.51,1.8635
91,,0.81,0.5094,0.54,1.8761
92,,0.83,0.4868,0.55,1.5972
93,,0.81,0.5290,0.53,1.2366
94,,0.82,0.5250,0.56,1.5573
95,,0.81,0.5332,0.58,1.6811
96,,0.82,0.5145,0.60,1.2656
97,,0.83,0.4826,0.63,1.4009
98,,0.80,0.5447,0.60,1.2594
99,,0.82,0.5181,0.59,1.4266
