,notes,train_acc,train_loss,val_acc,val_loss
0,,0.51,1.6192,0.44,1.4035
1,,0.63,1.1395,0.35,2.2781
2,,0.67,0.9910,0.50,1.5927
3,,0.71,0.9254,0.63,1.6060
4,,0.69,1.0256,0.62,1.3577
5,,0.71,0.8561,0.50,1.7247
6,created new Adam optimizer with LR: 0.00100000000000000002,0.69,1.0370,0.61,1.6492
7,,0.76,0.7909,0.31,2.9103
8,,0.74,0.7678,0.70,0.9526
9,,0.80,0.5527,0.65,1.1412
10,,0.82,0.4902,0.69,0.9678
11,,0.80,0.5369,0.64,1.0690
12,,0.78,0.5597,0.67,0.9945
13,created new Adam optimizer with LR: 0.0001,0.81,0.5154,0.70,0.9474
14,,0.81,0.5177,0.68,1.0756
15,,0.80,0.5154,0.64,1.3275
16,,0.83,0.4676,0.69,1.0407
17,,0.77,0.5875,0.64,1.2865
18,,0.80,0.5226,0.71,1.1133
19,,0.80,0.5254,0.64,1.3204
20,created new Adam optimizer with LR: 0.00001,0.81,0.4771,0.69,1.0366
21,,0.83,0.4537,0.70,0.9140
22,,0.84,0.4218,0.69,1.0644
23,,0.81,0.5102,0.66,1.1217
24,,0.81,0.5057,0.71,0.8618
25,,0.82,0.4531,0.63,1.2603
26,,0.82,0.4730,0.70,0.8156
27,created new Adam optimizer with LR: 0.000001,0.82,0.4767,0.68,0.9227
28,,0.83,0.4286,0.67,0.9892
29,,0.81,0.4716,0.65,1.2565
30,,0.81,0.4925,0.70,0.9415
31,,0.84,0.4307,0.71,0.9497
32,,0.81,0.4853,0.64,1.2023
33,,0.81,0.5011,0.69,0.8440
34,created new Adam optimizer with LR: 0.0000001,0.81,0.4887,0.65,1.3038
35,,0.82,0.4835,0.67,0.8863
36,,0.83,0.4618,0.71,0.9650
37,,0.82,0.4891,0.69,0.9623
38,,0.81,0.4882,0.67,1.5181
39,,0.80,0.5330,0.72,1.0351
40,,0.80,0.5078,0.64,1.0057
41,created new Adam optimizer with LR: 0.00000001,0.82,0.4718,0.64,1.1563
42,,0.84,0.4597,0.61,1.3120
43,,0.82,0.4753,0.72,0.8727
44,,0.83,0.4568,0.66,1.2462
45,,0.82,0.4604,0.71,0.9184
46,,0.80,0.5077,0.58,1.4863
47,,0.83,0.4524,0.65,1.1116
48,created new Adam optimizer with LR: 0.000000001,0.81,0.4720,0.72,0.8697
49,,0.82,0.4777,0.69,0.9531
