,notes,train_acc,train_loss,val_acc,val_loss
0,,0.58,1.4245,0.51,4.1798
1,,0.65,1.1827,0.24,7.9372
2,,0.69,1.1769,0.05,6.6506
3,,0.67,1.2775,0.59,4.1384
4,,0.65,1.2794,0.59,1.3858
5,,0.77,0.7529,0.63,1.5249
6,,0.75,0.9300,0.50,4.8973
7,,0.76,0.6868,0.52,1.8498
8,,0.75,0.7973,0.53,12.3680
9,,0.79,0.7082,0.60,1.4194
10,,0.81,0.6056,0.28,4.6090
11,,0.75,1.0213,0.66,0.9798
12,,0.78,0.7215,0.66,1.9042
13,,0.77,0.8057,0.30,5.5579
14,,0.81,0.7278,0.62,1.4568
15,,0.81,0.6092,0.39,4.6950
16,,0.82,0.6349,0.22,7.9952
17,,0.78,0.8458,0.62,2.6894
18,,0.81,0.6365,0.62,1.7453
19,,0.84,0.4906,0.67,1.1359
20,,0.83,0.5655,0.54,13.1665
21,,0.77,0.9794,0.65,2.1393
22,,0.81,0.7511,0.45,2.2024
23,,0.82,0.6535,0.37,7.5395
24,,0.84,0.6187,0.56,3.3298
25,,0.81,0.6899,0.58,8.7954
26,,0.86,0.4764,0.64,1.9371
27,,0.87,0.4442,0.50,2.8948
28,,0.85,0.4789,0.67,1.2567
29,,0.85,0.5465,0.62,4.4952
30,,0.78,0.9841,0.59,1.5879
31,,0.82,0.7247,0.52,2.7984
32,,0.81,0.7680,0.64,2.4352
33,,0.79,0.9752,0.65,1.3246
34,,0.86,0.5041,0.58,2.9014
35,,0.85,0.4654,0.67,2.2771
36,,0.80,0.7990,0.64,2.0448
37,,0.88,0.3750,0.64,2.2805
38,,0.85,0.5380,0.61,3.8512
39,created new Adam optimizer with LR: 0.00100000000000000002,0.84,0.5674,0.57,3.8008
40,,0.86,0.4686,0.46,2.4744
41,,0.83,0.5922,0.67,2.5802
42,,0.89,0.2735,0.72,1.2300
43,,0.87,0.3770,0.67,1.4878
44,,0.84,0.4522,0.63,2.3859
45,,0.88,0.3519,0.64,1.2467
46,,0.90,0.2879,0.56,15.5526
47,,0.91,0.2616,0.69,1.8343
48,,0.91,0.2555,0.71,1.2263
49,,0.90,0.2941,0.68,1.3751
50,,0.90,0.2719,0.70,1.5977
51,,0.88,0.3299,0.63,1.7741
52,,0.89,0.3085,0.72,1.7841
53,,0.88,0.2969,0.66,1.5061
54,,0.88,0.3511,0.66,1.5033
55,,0.89,0.3104,0.68,1.0878
56,,0.88,0.3677,0.59,1.7078
57,,0.87,0.3334,0.65,1.5190
58,,0.88,0.3414,0.62,3.8203
59,,0.90,0.2454,0.66,1.4930
60,,0.90,0.2838,0.64,1.8224
61,,0.90,0.2675,0.62,4.6946
62,,0.88,0.3272,0.68,2.6236
63,,0.89,0.3213,0.70,1.8998
64,,0.91,0.2415,0.65,1.3513
65,,0.89,0.3129,0.70,1.6927
66,,0.89,0.2799,0.66,1.5431
67,,0.91,0.2521,0.69,1.1439
68,,0.89,0.3071,0.63,3.7408
69,,0.90,0.2487,0.64,4.0371
70,,0.89,0.3130,0.67,3.3877
71,,0.91,0.2503,0.63,3.4832
72,,0.91,0.2255,0.65,2.6732
73,,0.89,0.2925,0.65,1.4780
74,,0.90,0.2692,0.67,1.9226
75,,0.89,0.2701,0.62,1.6266
76,,0.91,0.2287,0.69,1.0467
77,,0.90,0.2617,0.63,3.3021
78,,0.89,0.3351,0.70,1.5918
79,created new Adam optimizer with LR: 0.0001,0.86,0.3705,0.68,1.7572
80,,0.91,0.2379,0.65,3.1599
81,,0.90,0.2433,0.75,1.0954
82,,0.90,0.2585,0.71,1.4016
83,,0.90,0.2698,0.64,3.2301
84,,0.87,0.3188,0.59,5.0097
85,,0.92,0.2120,0.65,3.1794
86,,0.91,0.2545,0.76,1.0744
87,,0.93,0.1938,0.59,3.4273
88,,0.91,0.2506,0.59,3.0768
89,,0.92,0.2138,0.75,1.2097
90,,0.90,0.2501,0.72,1.3718
91,,0.88,0.3230,0.61,2.1678
92,,0.90,0.2463,0.68,1.2707
93,,0.91,0.2341,0.68,2.0178
94,,0.94,0.1789,0.70,1.4400
95,,0.91,0.2558,0.72,1.3021
96,,0.92,0.2221,0.63,4.0418
97,,0.88,0.3246,0.70,1.1638
98,,0.93,0.1998,0.71,2.5161
99,,0.91,0.2307,0.65,1.4872
