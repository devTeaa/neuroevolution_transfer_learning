,notes,train_acc,train_loss,val_acc,val_loss
0,,0.39,1.6284,0.43,1.7725
1,,0.41,1.5584,0.43,1.5440
2,,0.41,1.5759,0.24,1.5714
3,,0.41,1.5565,0.43,1.5615
4,,0.43,1.5837,0.43,1.6085
5,,0.43,1.5847,0.43,1.5413
6,,0.43,1.5785,0.43,1.5416
7,,0.41,1.5627,0.43,1.5420
8,,0.39,1.5823,0.43,1.5353
9,,0.41,1.5676,0.43,1.5327
10,,0.43,1.5675,0.43,1.5370
11,,0.41,1.5610,0.43,1.5350
12,,0.45,1.5570,0.43,1.5683
13,,0.43,1.5753,0.42,1.5260
14,,0.39,1.5678,0.42,1.5472
15,,0.38,1.5637,0.43,1.5235
16,,0.39,1.5686,0.43,1.5296
17,,0.43,1.5621,0.43,1.5260
18,,0.39,1.5626,0.43,1.5467
19,,0.39,1.5685,0.43,1.5502
20,,0.39,1.5698,0.43,1.5390
21,,0.43,1.5667,0.42,1.5295
22,,0.41,1.5618,0.43,1.5259
23,,0.43,1.5578,0.42,1.5247
24,,0.43,1.5615,0.43,1.5324
25,,0.41,1.5622,0.43,1.5253
26,,0.43,1.5633,0.43,1.5228
27,,0.39,1.5586,0.43,1.5237
28,,0.43,1.5614,0.43,1.5243
29,created new Adam optimizer with LR: 0.00100000000000000002,0.41,1.5524,0.42,1.5604
30,,0.43,1.5626,0.42,1.5494
31,,0.41,1.5668,0.42,1.5367
32,,0.41,1.5571,0.42,1.5301
33,,0.41,1.5545,0.43,1.5267
34,,0.41,1.5524,0.42,1.5246
35,,0.43,1.5508,0.42,1.5235
36,,0.41,1.5512,0.43,1.5229
37,,0.43,1.5511,0.43,1.5220
38,,0.41,1.5505,0.43,1.5217
39,,0.41,1.5503,0.42,1.5216
40,,0.41,1.5498,0.42,1.5215
41,,0.41,1.5502,0.43,1.5215
42,,0.43,1.5504,0.43,1.5214
43,,0.41,1.5506,0.43,1.5215
44,,0.41,1.5496,0.43,1.5224
45,,0.41,1.5501,0.42,1.5227
46,,0.43,1.5502,0.43,1.5227
47,,0.43,1.5497,0.42,1.5223
48,,0.39,1.5498,0.43,1.5217
49,,0.39,1.5502,0.43,1.5216
50,,0.41,1.5498,0.42,1.5219
51,,0.41,1.5501,0.43,1.5218
52,,0.41,1.5498,0.43,1.5220
53,,0.43,1.5505,0.43,1.5223
54,,0.39,1.5502,0.43,1.5223
55,,0.39,1.5500,0.43,1.5231
56,,0.41,1.5504,0.43,1.5235
57,,0.43,1.5504,0.42,1.5227
58,,0.43,1.5494,0.43,1.5217
59,created new Adam optimizer with LR: 0.0001,0.41,1.5501,0.42,1.5215
60,,0.41,1.5499,0.42,1.5220
61,,0.41,1.5489,0.42,1.5219
62,,0.41,1.5488,0.43,1.5220
63,,0.41,1.5488,0.43,1.5220
64,,0.41,1.5488,0.43,1.5220
65,,0.41,1.5489,0.43,1.5220
66,,0.41,1.5489,0.43,1.5220
67,,0.41,1.5488,0.43,1.5220
68,,0.41,1.5488,0.43,1.5220
69,,0.39,1.5488,0.42,1.5221
70,,0.45,1.5488,0.43,1.5221
71,,0.41,1.5489,0.42,1.5221
72,,0.43,1.5488,0.42,1.5220
73,,0.41,1.5488,0.42,1.5219
74,,0.45,1.5488,0.42,1.5219
75,,0.41,1.5488,0.43,1.5218
76,,0.41,1.5488,0.43,1.5218
77,,0.41,1.5488,0.43,1.5218
78,,0.41,1.5488,0.43,1.5218
79,,0.41,1.5488,0.43,1.5218
80,,0.45,1.5488,0.43,1.5218
81,,0.39,1.5488,0.43,1.5218
82,,0.41,1.5488,0.42,1.5219
83,,0.39,1.5488,0.43,1.5219
84,,0.39,1.5487,0.42,1.5220
85,,0.41,1.5488,0.43,1.5220
86,,0.43,1.5487,0.43,1.5220
87,,0.41,1.5488,0.43,1.5220
88,,0.41,1.5488,0.43,1.5220
89,created new Adam optimizer with LR: 0.00001,0.43,1.5487,0.43,1.5219
90,,0.43,1.5488,0.43,1.5219
91,,0.41,1.5486,0.43,1.5219
92,,0.43,1.5486,0.43,1.5219
93,,0.41,1.5486,0.43,1.5219
94,,0.43,1.5486,0.43,1.5219
95,,0.39,1.5486,0.43,1.5219
96,,0.39,1.5486,0.43,1.5219
97,,0.43,1.5486,0.42,1.5219
98,,0.41,1.5486,0.43,1.5219
99,,0.39,1.5486,0.42,1.5219
