,notes,train_acc,train_loss,val_acc,val_loss
0,,0.57,1.8713,0.43,2.2709
1,,0.71,1.0668,0.58,1.5160
2,,0.74,0.9004,0.41,3.6528
3,,0.77,0.9244,0.61,2.9342
4,,0.82,0.5906,0.61,3.0274
5,,0.82,0.6380,0.72,1.0201
6,,0.85,0.5445,0.49,2.0311
7,,0.81,0.6618,0.65,1.8387
8,,0.85,0.5588,0.55,2.0703
9,,0.86,0.4951,0.55,1.9690
10,,0.86,0.4787,0.61,1.6142
11,,0.88,0.4027,0.70,1.5282
12,,0.88,0.3796,0.61,1.8999
13,,0.86,0.4772,0.73,1.1541
14,,0.88,0.4533,0.72,1.0488
15,,0.89,0.3562,0.58,2.0956
16,,0.86,0.5493,0.70,1.4427
17,,0.88,0.4509,0.57,1.6691
18,,0.86,0.5120,0.55,2.1036
19,,0.90,0.3695,0.67,2.0424
20,,0.88,0.4091,0.72,1.0296
21,,0.90,0.3684,0.63,1.9759
22,,0.91,0.3133,0.63,1.9629
23,,0.89,0.3854,0.71,1.3732
24,,0.91,0.3204,0.64,2.6005
25,,0.90,0.3453,0.70,2.0765
26,,0.90,0.3763,0.72,1.3453
27,,0.92,0.2953,0.66,2.0573
28,,0.91,0.3506,0.62,2.8745
29,,0.90,0.3744,0.74,1.6437
30,,0.91,0.3293,0.70,1.4773
31,,0.90,0.3400,0.64,2.4085
32,,0.90,0.4180,0.69,1.4781
33,,0.92,0.2811,0.75,0.8890
34,,0.92,0.3461,0.71,1.3711
35,,0.90,0.3492,0.69,2.2199
36,,0.90,0.3825,0.72,1.6426
37,,0.90,0.3928,0.70,1.5222
38,,0.90,0.3752,0.72,1.2515
39,created new Adam optimizer with LR: 0.00100000000000000002,0.92,0.3038,0.75,1.7427
40,,0.92,0.2846,0.71,1.7125
41,,0.93,0.2593,0.75,1.1189
42,,0.94,0.2212,0.77,1.0167
43,,0.94,0.2029,0.77,0.9900
44,,0.94,0.1827,0.78,1.0169
45,,0.95,0.1779,0.78,0.9723
46,,0.95,0.1542,0.79,1.0170
47,,0.94,0.1901,0.78,0.9638
48,,0.95,0.1634,0.77,0.9443
49,,0.94,0.1949,0.78,0.9575
50,,0.95,0.1374,0.78,0.9698
51,,0.95,0.1352,0.77,1.0618
52,,0.94,0.1914,0.78,1.0088
53,,0.95,0.1775,0.78,0.9726
54,,0.95,0.1550,0.78,0.9498
55,,0.95,0.1566,0.75,1.0532
56,,0.94,0.1910,0.77,1.1180
57,,0.94,0.1834,0.77,1.0096
58,,0.96,0.1324,0.76,0.9888
59,,0.95,0.1873,0.78,0.9597
60,,0.95,0.1670,0.77,0.9390
61,,0.95,0.1676,0.77,1.1040
62,,0.95,0.1663,0.78,0.9801
63,,0.95,0.1652,0.80,0.8873
64,,0.95,0.1406,0.79,0.9202
65,,0.95,0.1533,0.77,1.0124
66,,0.94,0.1921,0.76,1.0724
67,,0.94,0.1929,0.78,0.9495
68,,0.95,0.1764,0.78,0.9594
69,,0.95,0.1726,0.77,0.9835
70,,0.95,0.1513,0.77,0.9555
71,,0.95,0.1561,0.78,0.8973
72,,0.95,0.1348,0.78,0.8515
73,,0.95,0.1505,0.76,0.9478
74,,0.96,0.1435,0.77,0.8960
75,,0.96,0.1409,0.76,0.9347
76,,0.94,0.1752,0.75,1.0165
77,,0.95,0.1543,0.77,0.9640
78,,0.96,0.1239,0.76,0.9140
79,created new Adam optimizer with LR: 0.0001,0.95,0.1596,0.77,0.9248
80,,0.96,0.1349,0.75,0.9526
81,,0.96,0.1157,0.76,0.9397
82,,0.96,0.1284,0.76,0.9255
83,,0.95,0.1550,0.76,0.9330
84,,0.96,0.1199,0.76,0.9430
85,,0.95,0.1576,0.75,0.9431
86,,0.95,0.1636,0.76,0.9546
87,,0.96,0.1180,0.76,0.9589
88,,0.96,0.1181,0.76,0.9366
89,,0.95,0.1438,0.77,0.9384
90,,0.95,0.1525,0.76,0.9353
91,,0.95,0.1441,0.76,0.9288
92,,0.96,0.1289,0.76,0.9405
93,,0.96,0.1352,0.78,0.9278
94,,0.96,0.1162,0.76,0.9426
95,,0.96,0.1306,0.77,0.9499
96,,0.95,0.1447,0.77,0.9404
97,,0.96,0.1243,0.76,0.9466
98,,0.96,0.1280,0.76,0.9143
99,,0.95,0.1425,0.78,0.9155
