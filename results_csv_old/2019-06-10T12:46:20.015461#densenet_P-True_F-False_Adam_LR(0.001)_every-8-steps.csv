,notes,train_acc,train_loss,val_acc,val_loss
0,,0.58,1.4454,0.43,1.7780
1,,0.47,1.5585,0.37,4.1594
2,,0.49,1.5785,0.46,3.3554
3,,0.50,1.4300,0.30,3.0189
4,,0.52,1.3539,0.23,109.9081
5,,0.46,1.4420,0.35,6.1031
6,,0.48,1.3981,0.28,2.2161
7,created new Adam optimizer with LR: 0.00100000000000000002,0.49,1.4011,0.37,10.7035
8,,0.53,1.3224,0.29,19.3492
9,,0.52,1.3545,0.41,2.7365
10,,0.55,1.1983,0.57,1.2812
11,,0.57,1.0867,0.47,2.7809
12,,0.58,1.1013,0.48,5.2221
13,,0.57,1.0872,0.36,5.0778
14,,0.61,1.0224,0.45,6.1499
15,created new Adam optimizer with LR: 0.0001,0.60,0.9956,0.36,44.2902
16,,0.62,1.0072,0.49,2.6764
17,,0.63,0.9711,0.46,8.1630
18,,0.65,0.9162,0.48,23.6529
19,,0.65,0.9415,0.47,8.8037
20,,0.68,0.9129,0.45,24.0282
21,,0.68,0.8783,0.38,29.3997
22,,0.68,0.8744,0.53,4.1504
23,created new Adam optimizer with LR: 0.00001,0.65,0.9089,0.48,3.1687
24,,0.64,0.9240,0.34,47.7649
25,,0.66,0.8895,0.40,43.6865
26,,0.69,0.8490,0.43,68.9597
27,,0.70,0.8582,0.34,25.3093
28,,0.69,0.8693,0.43,32.9213
29,,0.68,0.8479,0.48,11.0113
30,,0.69,0.8454,0.51,9.6044
31,created new Adam optimizer with LR: 0.000001,0.68,0.8568,0.45,88.4598
32,,0.66,0.8573,0.43,35.7860
33,,0.67,0.8497,0.53,8.3269
34,,0.69,0.8812,0.55,20.9734
35,,0.69,0.8667,0.54,15.6703
36,,0.67,0.8563,0.58,2.9287
37,,0.67,0.8811,0.47,38.9655
38,,0.68,0.8338,0.54,14.4557
39,created new Adam optimizer with LR: 0.0000001,0.69,0.8511,0.54,11.9298
40,,0.69,0.8535,0.55,4.6921
41,,0.69,0.8604,0.32,48.6340
42,,0.68,0.9136,0.38,26.1574
43,,0.67,0.8617,0.48,29.0871
44,,0.66,0.8833,0.35,175.7432
45,,0.70,0.8487,0.34,47.3771
46,,0.69,0.8490,0.47,16.8495
47,created new Adam optimizer with LR: 0.00000001,0.70,0.8476,0.40,7.6994
48,,0.74,0.7773,0.43,18.1105
49,,0.69,0.8392,0.51,14.1047
