,notes,train_acc,train_loss,val_acc,val_loss
0,,0.52,1.4424,0.43,1.8416
1,,0.48,1.4125,0.43,1.6088
2,,0.45,1.5108,0.16,2.5236
3,,0.47,1.4921,0.43,1.5918
4,,0.49,1.4350,0.24,12.1086
5,,0.47,1.4651,0.43,2.1281
6,,0.49,1.4517,0.25,1.7776
7,,0.42,1.5281,0.24,1.6358
8,,0.44,1.4927,0.42,1.9324
9,,0.50,1.4374,0.25,7.6661
10,,0.49,1.4154,0.24,2.2668
11,,0.49,1.4341,0.43,9.5905
12,,0.49,1.4089,0.43,1.6749
13,,0.51,1.4213,0.16,4.3878
14,,0.48,1.4923,0.42,2.0182
15,,0.53,1.4024,0.43,1.6360
16,,0.50,1.4161,0.43,1.7371
17,,0.53,1.3204,0.43,2.2983
18,,0.53,1.3343,0.43,2.6366
19,,0.53,1.3711,0.25,1.7378
20,,0.54,1.2974,0.43,1.7213
21,,0.14,nan,0.02,nan
22,,0.02,nan,0.02,nan
23,,0.02,nan,0.02,nan
24,,0.02,nan,0.02,nan
25,,0.02,nan,0.02,nan
26,,0.02,nan,0.02,nan
27,,0.02,nan,0.02,nan
28,,0.02,nan,0.02,nan
29,created new Adam optimizer with LR: 0.00100000000000000002,0.03,nan,0.02,nan
30,,0.02,nan,0.02,nan
31,,0.02,nan,0.02,nan
32,,0.02,nan,0.02,nan
33,,0.03,nan,0.02,nan
34,,0.02,nan,0.02,nan
35,,0.02,nan,0.02,nan
36,,0.02,nan,0.02,nan
37,,0.02,nan,0.02,nan
38,,0.02,nan,0.02,nan
39,,0.02,nan,0.02,nan
40,,0.02,nan,0.02,nan
41,,0.02,nan,0.02,nan
42,,0.02,nan,0.02,nan
43,,0.02,nan,0.02,nan
44,,0.02,nan,0.02,nan
45,,0.02,nan,0.02,nan
46,,0.02,nan,0.02,nan
47,,0.02,nan,0.02,nan
48,,0.02,nan,0.02,nan
49,,0.02,nan,0.02,nan
