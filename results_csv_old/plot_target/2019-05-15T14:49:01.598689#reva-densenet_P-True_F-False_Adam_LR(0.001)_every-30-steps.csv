,notes,train_acc,train_loss,val_acc,val_loss
0,,0.48,1.5170,0.28,1.6861
1,,0.45,1.4815,0.42,2.1825
2,,0.42,1.5201,0.25,1.7242
3,,0.50,1.4449,0.43,2.3956
4,,0.51,1.3980,0.43,2.0766
5,,0.51,1.3748,0.42,1.6929
6,,0.48,1.4873,0.44,1.6097
7,,0.45,1.4592,0.43,36.0071
8,,0.04,nan,0.02,nan
9,,0.02,nan,0.02,nan
10,,0.02,nan,0.02,nan
11,,0.02,nan,0.02,nan
12,,0.02,nan,0.02,nan
13,,0.02,nan,0.02,nan
14,,0.02,nan,0.02,nan
15,,0.02,nan,0.02,nan
16,,0.02,nan,0.02,nan
17,,0.02,nan,0.02,nan
18,,0.02,nan,0.02,nan
19,,0.02,nan,0.02,nan
20,,0.02,nan,0.02,nan
21,,0.02,nan,0.02,nan
22,,0.02,nan,0.02,nan
23,,0.02,nan,0.02,nan
24,,0.02,nan,0.02,nan
25,,0.02,nan,0.02,nan
26,,0.02,nan,0.02,nan
27,,0.02,nan,0.02,nan
28,,0.02,nan,0.02,nan
29,created new Adam optimizer with LR: 0.00100000000000000002,0.02,nan,0.02,nan
30,,0.02,nan,0.02,nan
31,,0.02,nan,0.02,nan
32,,0.02,nan,0.02,nan
33,,0.02,nan,0.02,nan
34,,0.02,nan,0.02,nan
35,,0.02,nan,0.02,nan
36,,0.02,nan,0.02,nan
37,,0.02,nan,0.02,nan
38,,0.02,nan,0.02,nan
39,,0.02,nan,0.02,nan
40,,0.02,nan,0.02,nan
41,,0.02,nan,0.02,nan
42,,0.02,nan,0.02,nan
43,,0.02,nan,0.02,nan
44,,0.02,nan,0.02,nan
45,,0.02,nan,0.02,nan
46,,0.02,nan,0.02,nan
47,,0.02,nan,0.02,nan
48,,0.02,nan,0.02,nan
49,,0.02,nan,0.02,nan
