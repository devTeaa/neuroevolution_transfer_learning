,notes,train_acc,train_loss,val_acc,val_loss
0,,0.60,1.2357,0.04,5.0204
1,,0.64,1.0898,0.04,5.9925
2,,0.66,0.9707,0.04,4.8226
3,,0.73,0.7621,0.16,5.5864
4,,0.79,0.5913,0.16,7.4761
5,,0.79,0.5827,0.16,6.8686
6,,0.86,0.4157,0.16,7.4438
7,created new Adam optimizer with LR: 0.00100000000000000002,0.89,0.3090,0.16,8.0854
8,,0.87,0.3733,0.16,10.2890
9,,0.90,0.2802,0.16,8.6393
10,,0.93,0.1940,0.16,9.6674
11,,0.92,0.2156,0.16,8.1287
12,,0.92,0.2049,0.16,10.2519
13,,0.93,0.1920,0.16,10.9317
14,,0.97,0.1147,0.16,11.2728
15,created new Adam optimizer with LR: 0.0001,0.96,0.1468,0.16,10.3397
16,,0.96,0.1547,0.16,10.4634
17,,0.97,0.1122,0.16,8.6638
18,,0.97,0.1100,0.16,10.8916
19,,0.96,0.1540,0.16,10.2877
20,,0.94,0.1512,0.16,7.7725
21,,0.98,0.0877,0.16,10.6025
22,,0.98,0.0936,0.16,10.7316
23,created new Adam optimizer with LR: 0.00001,0.97,0.1108,0.16,9.5800
24,,0.97,0.1187,0.16,10.7774
25,,0.95,0.1561,0.16,10.6937
26,,0.98,0.0720,0.16,10.8622
27,,0.98,0.0747,0.16,11.8171
28,,0.95,0.1404,0.16,10.0937
29,,0.96,0.1413,0.16,10.5667
30,,0.98,0.0936,0.16,11.1947
31,created new Adam optimizer with LR: 0.000001,0.96,0.1303,0.16,8.8037
32,,0.98,0.0838,0.16,8.7573
33,,0.98,0.0955,0.16,11.8990
34,,0.96,0.1233,0.16,10.2518
35,,0.97,0.0945,0.16,10.7234
36,,0.97,0.1078,0.16,9.6130
37,,0.97,0.0980,0.16,10.4601
38,,0.98,0.0927,0.16,8.5482
39,created new Adam optimizer with LR: 0.0000001,0.98,0.0845,0.16,10.7460
40,,0.95,0.1208,0.16,11.5508
41,,0.99,0.0844,0.16,10.9824
42,,0.98,0.0771,0.16,10.3196
43,,0.97,0.1076,0.16,10.7414
44,,0.99,0.0756,0.16,9.3385
45,,0.97,0.0902,0.16,9.3965
46,,0.98,0.0877,0.16,11.3707
47,created new Adam optimizer with LR: 0.00000001,0.97,0.1044,0.16,9.5990
48,,0.98,0.0817,0.16,10.4109
49,,0.97,0.1206,0.16,9.1885
