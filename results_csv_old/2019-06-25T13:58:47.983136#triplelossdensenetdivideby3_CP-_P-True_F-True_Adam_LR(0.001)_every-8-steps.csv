,notes,train_acc,train_loss,val_acc,val_loss
0,,0.54,1.5262,0.07,11.1682
1,,0.59,1.3219,0.43,9.0985
2,,0.61,1.2710,0.04,12.6801
3,,0.63,1.1185,0.04,12.1222
4,,0.73,0.9306,0.16,13.2466
5,,0.76,0.7925,0.02,13.6871
6,,0.77,0.8659,0.08,24.9897
7,created new Adam optimizer with LR: 0.00100000000000000002,0.79,0.8196,0.07,19.5567
8,,0.84,0.6860,0.07,21.4238
9,,0.83,0.6683,0.07,22.3175
10,,0.93,0.4828,0.08,22.7758
11,,0.97,0.4267,0.07,21.5729
12,,0.93,0.4672,0.07,22.1418
13,,0.95,0.4562,0.08,25.0450
14,,0.94,0.4689,0.08,24.4817
15,created new Adam optimizer with LR: 0.0001,0.96,0.4452,0.07,24.7472
16,,0.96,0.4414,0.07,25.7830
17,,0.96,0.4296,0.07,24.1921
18,,0.98,0.3929,0.09,22.0221
19,,0.95,0.4368,0.08,24.4488
20,,0.98,0.3778,0.08,23.3042
21,,0.98,0.3871,0.08,20.8676
22,,0.96,0.4417,0.07,26.0978
23,created new Adam optimizer with LR: 0.00001,0.97,0.4355,0.07,23.1253
24,,0.97,0.3895,0.07,21.8828
25,,0.97,0.3783,0.08,24.0898
26,,0.98,0.3940,0.08,23.2974
27,,0.95,0.4495,0.08,25.8875
28,,0.96,0.4355,0.07,23.7751
29,,0.97,0.4018,0.08,23.9160
30,,0.98,0.3955,0.08,25.0623
31,created new Adam optimizer with LR: 0.000001,0.97,0.4059,0.08,23.9016
32,,0.98,0.3988,0.08,25.0436
33,,0.98,0.3833,0.07,23.3470
34,,0.97,0.4036,0.08,24.2035
35,,0.98,0.4016,0.07,22.5701
36,,0.96,0.4239,0.07,24.1035
37,,0.96,0.4158,0.07,23.3046
38,,0.97,0.3919,0.07,23.6531
39,created new Adam optimizer with LR: 0.0000001,0.96,0.4156,0.07,24.0828
40,,0.98,0.4020,0.07,25.7946
41,,0.98,0.3882,0.07,24.4419
42,,0.98,0.3925,0.07,25.0711
43,,0.98,0.3831,0.07,24.7019
44,,0.98,0.3803,0.07,25.1645
45,,0.97,0.4072,0.07,24.1243
46,,0.95,0.4257,0.07,23.7250
47,created new Adam optimizer with LR: 0.00000001,0.98,0.3858,0.07,23.8964
48,,0.98,0.3812,0.07,25.4963
49,,0.99,0.3821,0.07,24.5228
